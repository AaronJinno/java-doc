import{_ as a,o as e,c as n,e as i}from"./app-ff4af090.js";const s="/java-doc/img/sql/es/5-5-1.jpg",r="/java-doc/img/sql/es/5-5-2.jpg",d={},l=i('<p>分片是 Elasticsearch 最小的工作单元。</p><h2 id="索引分段" tabindex="-1"><a class="header-anchor" href="#索引分段" aria-hidden="true">#</a> 索引分段</h2><h4 id="_1-早期文档搜索的做法" tabindex="-1"><a class="header-anchor" href="#_1-早期文档搜索的做法" aria-hidden="true">#</a> 1. 早期文档搜索的做法</h4><p>早期的全文检索会为整个文档集合建立一个很大的倒排索引并将其写入到磁盘。 一旦新的索引就绪，旧的就会被其替换，这样最近的变化便可以被检索到。</p><p>倒排索引被写入磁盘后是不可改变的，它永远不会修改。</p><h5 id="_1-1-不变性的优点" tabindex="-1"><a class="header-anchor" href="#_1-1-不变性的优点" aria-hidden="true">#</a> 1.1 不变性的优点</h5><ul><li>不需要锁。如果从来不更新索引，你就不需要担心多进程同时修改数据的问题。</li><li>一旦索引被读入内核的文件系统缓存，便会留在哪里，由于其不变性。只要文件系统缓存中还有足够的空间，那么大部分读请求会直接请求内存，而不会命中磁盘。这提供了很大的性能提升。</li><li>其它缓存(像 filter 缓存)，在索引的生命周期内始终有效。它们不需要在每次数据改变时被重建，因为数据不会变化。</li><li>写入单个大的倒排索引允许数据被压缩，减少磁盘 I/O 和 需要被缓存到内存的索引的使用量</li></ul><h5 id="_1-2-不变性的缺点" tabindex="-1"><a class="header-anchor" href="#_1-2-不变性的缺点" aria-hidden="true">#</a> 1.2 不变性的缺点</h5><p>既然不变了，就无法修改倒排索引本身，而只能进行替换，如果新增了一个文档，想被搜索到，就需要重构整个索引。</p><p>这样的话就非常麻烦，只能采取定时（比如一周更新一次）更新的策略。</p><h4 id="_2-动态更新索引" tabindex="-1"><a class="header-anchor" href="#_2-动态更新索引" aria-hidden="true">#</a> 2. 动态更新索引</h4><p>需求：保证不变性的前提下实现倒排索引的更新？<br> 方案：使用更多的索引，进行增量更新！</p><p>通过增加新的补充索引来反映新近的修改，而不是直接重写整个倒排索引。每一个倒排索引都会被轮流查询到，从最早的开始查询完后再对结果进行合并。</p><h4 id="_3-动态更新的过程" tabindex="-1"><a class="header-anchor" href="#_3-动态更新的过程" aria-hidden="true">#</a> 3. 动态更新的过程</h4><p>当产生了新的文档时，就需要将文档进行动态更新，更新过程如下：</p><figure><img src="'+s+'" alt="5-5-1" tabindex="0" loading="lazy"><figcaption>5-5-1</figcaption></figure><ul><li>客户端提交新的文档到集群</li><li>协调节点根据文档的_id计算要放入的主分片（PO）</li><li>主分片写入更新</li><li>主分片将更新复制到副分片RO和R1 <ul><li>这两个复制是同时进行的，不过完成复制的时间不一定相同。</li></ul></li><li>副分片更新完后，整个更新流程结束，向客户端响应</li></ul><p>根据上面的更新流程可知，更新是有延迟的：</p><p><mark>延时 = 主分片延时 + 并行写入副本的最大延时</mark></p><h4 id="_4-按段搜索" tabindex="-1"><a class="header-anchor" href="#_4-按段搜索" aria-hidden="true">#</a> 4. 按段搜索</h4><p>因为是按增量更新的，每更新就新建了一个倒排索引，因此搜索的时候需要每个倒排索引都进行搜索，一个倒排索引就是一段，这个搜索过程就称为：按段搜索。</p><p>当一个查询被触发，所有已知的段按顺序被查询。词项统计会对所有段的结果进行聚合，以保证每个词和每个文档的关联都被准确计算。这种方式可以用相对较低的成本将新文档添加到索引。</p><h4 id="_5-提交点" tabindex="-1"><a class="header-anchor" href="#_5-提交点" aria-hidden="true">#</a> 5. 提交点</h4><p>Elasticsearch 基于 Lucene, 这个 java 库引入了按段搜索的概念。 每一段本身都是一个倒排索引，但索引在 Lucene 中除表示所有段的集合外， 还增加了提交点的概念：一个列出了所有已知段的文件。</p><h4 id="_6-删除操作" tabindex="-1"><a class="header-anchor" href="#_6-删除操作" aria-hidden="true">#</a> 6. 删除操作</h4><p>段是不可改变的，所以既不能从把文档从旧的段中移除，也不能修改旧的段来进行反映文档<br> 的更新，那么如何处理增量更新后 之前的旧版本文档，以及如何删除文档呢？</p><p>删除：每个提交点会包含一个 .del 文件，文件中会列出这些被删除文档的段信息。当一个文档被 “删除” 时，它实际上只是在 .del 文件中被标记删除。一个被标记删除的文档仍然可以被查询匹配到， 但它会在最终结果被返回前从结果集中移除。</p><p>更新：文档更新也是类似的操作方式：当一个文档被更新时，旧版本文档被标记删除，文档的新版本被索引到一个新的段中。 可能两个版本的文档都会被一个查询匹配到，但被删除的那个旧版本文档在结果集返回前就已经被移除。</p><p>PS：不用担心无效文档越积越多，段合并的时候，会删除他们的。</p><h2 id="更新的生效" tabindex="-1"><a class="header-anchor" href="#更新的生效" aria-hidden="true">#</a> 更新的生效</h2><p>更新生效：指的是更新能被搜索到。</p><h4 id="_1-更新生效的流程" tabindex="-1"><a class="header-anchor" href="#_1-更新生效的流程" aria-hidden="true">#</a> 1. 更新生效的流程</h4><p>索引底层是按段更新的，更新最终要写入磁盘后才能生效，写入磁盘生效的过程如下：</p><figure><img src="'+r+`" alt="5-5-2" tabindex="0" loading="lazy"><figcaption>5-5-2</figcaption></figure><ul><li>内存（Memory）：首先，新文档被收集到内存索引缓存</li><li>内存-&gt;OS Cache：缓存被不断的刷写（refresh）到OS Cache <ul><li>OS Cache：同样也是内存，而非硬盘，OS Cache是为了减少磁盘IO参数的，当数据被刷到OS Cache时，就已经可以被查询到了。</li><li>直接刷到硬盘：直接刷写到硬盘也是可以的，只是IO的效率很低。更新生效需要的时间更长。</li></ul></li><li>OS Cache-&gt;磁盘（Disk）：将内存中的数据写入到磁盘（物理文件） <ul><li>磁盘创建新的段：一个追加的倒排索引</li><li>OS Cache中的数据被定时（30min）刷新（flush）到磁盘</li><li>一个新的包含新段名字的提交点也同时被写入磁盘</li></ul></li><li>磁盘（Disk）：新的段被开启，让它包含的文档可以被搜索</li><li>内存（Memory &amp; OS Cache）：内存缓存被清空，等待接收新的文档</li></ul><h4 id="_2-近实时搜索" tabindex="-1"><a class="header-anchor" href="#_2-近实时搜索" aria-hidden="true">#</a> 2. 近实时搜索</h4><p>新增文档，会以每秒一次的频次从 <code>内存索引缓存</code> 刷写到 <code>OS Cache</code> ，OS Cache里的文件已经可以查询了（只是没有持久化）。</p><p>这就是为什么我们说 Elasticsearch 是近实时搜索: 文档的变化并不是立即对搜索可见，但会在一秒之内变为可见。</p><h4 id="_3-更新控制" tabindex="-1"><a class="header-anchor" href="#_3-更新控制" aria-hidden="true">#</a> 3. 更新控制</h4><h5 id="_3-1-手动刷新" tabindex="-1"><a class="header-anchor" href="#_3-1-手动刷新" aria-hidden="true">#</a> 3.1 手动刷新</h5><p>当用户索引了一个文件并立即搜索它时，会发现根本搜不到，这会给用户产生困惑。</p><p>解决方法：用 refresh API 执行一次手动刷新: <code>/users/_refresh</code></p><p>当写测试的时候， 手动刷新很有用，但是不要在生产环境下每次索引一个文档都去手动刷新。 相反，你的应用需要意识到 Elasticsearch 的近实时的性质，并接受它的不足。</p><h5 id="_3-2-时效与效率的选择" tabindex="-1"><a class="header-anchor" href="#_3-2-时效与效率的选择" aria-hidden="true">#</a> 3.2 时效与效率的选择</h5><p>并不是所有的情况都需要每秒刷新。</p><p>比如：在使用 Elasticsearch 索引大量的日志文件，你可能想优化索引速度而不是近实时搜索， 可以通过设置 refresh_interval ， 降低每个索引的刷新频率</p><div class="language-json line-numbers-mode" data-ext="json"><pre class="language-json"><code><span class="token punctuation">{</span>
    <span class="token property">&quot;settings&quot;</span><span class="token operator">:</span> <span class="token punctuation">{</span>
        <span class="token property">&quot;refresh_interval&quot;</span><span class="token operator">:</span> <span class="token string">&quot;30s&quot;</span> 
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h5 id="_3-3-自动刷新的关闭与开启" tabindex="-1"><a class="header-anchor" href="#_3-3-自动刷新的关闭与开启" aria-hidden="true">#</a> 3.3 自动刷新的关闭与开启</h5><p>在生产环境中，当你正在建立一个大的新索引时，可以先关闭自动刷新，待开始使用该索引时，再把它们调回来</p><p>请求：PUT /users/_settings</p><div class="language-json line-numbers-mode" data-ext="json"><pre class="language-json"><code><span class="token comment">// 关闭自动刷新</span>
<span class="token punctuation">{</span> 
    <span class="token property">&quot;refresh_interval&quot;</span><span class="token operator">:</span> <span class="token number">-1</span> 
<span class="token punctuation">}</span>
 
<span class="token comment">// 每一秒刷新</span>
<span class="token punctuation">{</span>
    <span class="token property">&quot;refresh_interval&quot;</span><span class="token operator">:</span> <span class="token string">&quot;1s&quot;</span> 
<span class="token punctuation">}</span> 
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="_4-一致性问题-持久化变更" tabindex="-1"><a class="header-anchor" href="#_4-一致性问题-持久化变更" aria-hidden="true">#</a> 4. 一致性问题：持久化变更</h4><p>问题：内存中的数据向内存中刷写时可能会遇到突发状况，导致写入失败，这是可能会导致数据丢失。</p><p>解决方案：和MySQL的解决方案一样，通过Translog日志来解决。</p><h2 id="段合并" tabindex="-1"><a class="header-anchor" href="#段合并" aria-hidden="true">#</a> 段合并</h2><p>于自动刷新流程每秒会创建一个新的段，这样会导致短时间内的段数量暴增。而段数目太多会带来较大的麻烦。</p><p>每一个段都会消耗文件句柄、内存和 cpu 运行周期。更重要的是，每个搜索请求都必须轮流检查每个段；所以段越多，搜索也就越慢。</p><h4 id="_1-自动段合并" tabindex="-1"><a class="header-anchor" href="#_1-自动段合并" aria-hidden="true">#</a> 1. 自动段合并</h4><p>Elasticsearch 在后台可以进行自动段合并，小的段被合并到大的段，然后这些大的段再被合并到更大的段。</p><p>启动段合并不需要你做任何事。进行索引和搜索时会自动进行。</p><h4 id="_2-无效的文档" tabindex="-1"><a class="header-anchor" href="#_2-无效的文档" aria-hidden="true">#</a> 2. 无效的文档</h4><p>段合并的时候会将那些旧的已删除文档从文件系统中清除。被删除的文档（或被更新文档的旧版本）不会被拷贝到新的大段中。</p>`,62),t=[l];function c(h,p){return e(),n("div",null,t)}const u=a(d,[["render",c],["__file","5-5.分片原理.html.vue"]]);export{u as default};
