---
title: 4-2. windows集群
date: 2023-06-28
---
:::warning
仅做了解，开发中和生产中都不会使用Windows环境。

环境以ElasticSearch 8.8.1 为例
:::

集群要配置在多台电脑才有意义，这里仅做测试，在一台电脑上模拟集群，通过端口号区分。
## 准备
#### 1. 创建节点
创建 es-cluster 文件夹，在内部复制三个ES软件包，如果是复制之前的单节点es目录，记得删除data目录，清空logs目录

![4-2-1](/img/sql/es/4-2-1.jpg)

如上创建了三个节点：设计的端口号为9300，9400，9500

#### 2. 配置内存
:::danger
这一步非常重要，很多教程都没有提及，不配置可能要遭遇严重bug。

尤其是练习集群配置，将多个节点部署到一台电脑上。
:::
ES是基于Java的，启动ES时会同时启动自身内置的JVM。

ES的配置中，默认为JVM分配了4G的内存，当电脑内存不足时，就会报错。且每启动一个节点，就会占用4G内存。假如电脑只有8G内存，启动第二个节点时就必然会闪退。

##### 报错信息如下
通过powershell手动执行才能不闪退，从而看到报错信息

![4-2-2](/img/sql/es/4-2-2.jpg)

##### 手动指定JVM的内存
为了避免内存不足，根据电脑内存大小，手动指定JVM的内存占用，比如设置为512m

JVM配置文件：`config/jvm.options`
```js
################################################################
## IMPORTANT: JVM heap size
################################################################
##
## The heap size is automatically configured by Elasticsearch
## based on the available memory in your system and the roles
## each node is configured to fulfill. If specifying heap is
## required, it should be done through a file in jvm.options.d,
## which should be named with .options suffix, and the min and
## max should be set to the same value. For example, to set the
## heap to 4 GB, create a new file in the jvm.options.d
## directory containing these lines:
##
## -Xms4g
## -Xmx4g

-Xms512m 
-Xms512m
```
如上，手动指定JVM内存占用为512m，防止发生闪退故障。


## 配置节点
修改集群文件目录中每个节点的 config/elasticsearch.yml 配置文件

需要配置的内容：
- 名称
    - `cluster.name`：集群名称，节点之间要保持一致
    - `node.name`：节点名称，集群内要唯一
- 节点类型    
    - node.roles: [ master,data ]，节点所属的角色
        - master：表示可以被选举为主节点
        - data：表示该结点是数据结点，用于保存数据，执行数据相关的操作
    - cluster.initial_master_nodes：初始主节点
        - 当开启一个全新的集群时，会有一个集群的引导步骤，这步骤用来确定哪些节点参与第一次的主节点选举
        - ==必须且只能在第一个启动的节点处配置==，配置是`node.name`
        - 值必须包含当前节点，不然启动节点时，就选举不出主节点了
- 通信信息
    - network.host：ip地址，localhost表示本机地址
    - http.port: 端口
    - transport.port：tcp 监听端口，用于节点内部通信
- 发现模块，用于发现其他节点
    - discovery.seed_hosts: 被查询发现的其他节点的[ ip:transport.port ]
- 跨域配置
    - http.cors.enabled: 是否允许跨域
    - http.cors.allow-origin:  允许跨域的目录，`*` 表示所有目录

#### 1. 节点1：es-9300
```yaml
#节点 1 的配置信息：

#集群名称，节点之间要保持一致
cluster.name: my-es
#节点名称，集群内要唯一
node.name: node-9300


#ip 地址
network.host: localhost # 本机地址
#http 端口
http.port: 9300
#tcp 监听端口
transport.port: 9301

# 发现模块，用于发现其他节点，这里的端口是transport.port
# 第一个节点，可以不配置discovery.seed_hosts，因为启动时，只有他自己
discovery.seed_hosts: ["localhost:9401","localhost:9501"]

# 初始主节点：必须包含当前节点
cluster.initial_master_nodes: ["node-9300"]

# 跨域配置
http.cors.enabled: true
http.cors.allow-origin: "*"
```


#### 2.2 节点2：es-9400
```yaml
#节点 2 的配置信息：

#集群名称，节点之间要保持一致
cluster.name: my-es
#节点名称，集群内要唯一
node.name: node-9400


#ip 地址
network.host: localhost # 本机地址
#http 端口
http.port: 9400
#tcp 监听端口
transport.port: 9401

# 发现模块，用于发现其他节点，这里的端口是transport.port
discovery.seed_hosts: ["localhost:9301","localhost:9501"]

# 初始主节点 除了第一个节点，其他节点，一定不能配置该值，否则闪退
# cluster.initial_master_nodes:

# 跨域配置
http.cors.enabled: true
http.cors.allow-origin: "*"
```

#### 2.3 节点3：es-9500
```yaml
#节点 2 的配置信息：

#集群名称，节点之间要保持一致
cluster.name: my-es
#节点名称，集群内要唯一
node.name: node-9500


#ip 地址
network.host: localhost # 本机地址
#http 端口
http.port: 9500
#tcp 监听端口
transport.port: 9501

# 发现模块，用于发现其他节点，这里的端口是transport.port
discovery.seed_hosts: ["localhost:9301","localhost:9401"]

# 初始主节点 除了第一个节点，其他节点，一定不能配置该值，否则闪退
# cluster.initial_master_nodes:

# 跨域配置
http.cors.enabled: true
http.cors.allow-origin: "*"
```


## 启动集群
:::tip 注意事项
- 在修改配置文件之前，先依次启动一次所有节点，这样配置文件中跟安全有关的配置就会显示出来。这样方便配置忽略安全检测，启动完后，记得删除data目录，清空logs目录
- 启动节点是有顺序的，第一个启动的节点必须包含cluster.initial_master_nodes配置
:::

配置好一个节点，就启动一个，观察集群信息。

#### 1. 启动第一个节点：es-9300
这是启动的第一个节点，该节点必须包含cluster.initial_master_nodes配置

启动后，查看集群信息：
- 请求方式：GET
- url地址：http://localhost:9300/_cluster/health

返回的信息如下：
```json
{
    "cluster_name": "my-es",  // 集群名称
    "status": "green",  //集群状态，green表示健康
    "timed_out": false, //是否超时
    "number_of_nodes": 1, //节点数量，只启动了一个，所以是1
    "number_of_data_nodes": 1, //数据节点数量，只启动了一个，所以是1
    "active_primary_shards": 0,
    "active_shards": 0,
    "relocating_shards": 0,
    "initializing_shards": 0,
    "unassigned_shards": 0,
    "delayed_unassigned_shards": 0,
    "number_of_pending_tasks": 0,
    "number_of_in_flight_fetch": 0,
    "task_max_waiting_in_queue_millis": 0,
    "active_shards_percent_as_number": 100.0
}
```
"status"：集群状态：
- green：健康，所有主分片和副本分片都正常运行
- yellow：所有主分片都正常运行，但不是所有的副本分片都正常运行
- red：有主分片没能正常运行

#### 2. 启动第二个节点：es-9400
启动后，再次查看集群信息：

访问方式和地址不变
```json
{
    "cluster_name": "my-es",
    "status": "green",
    "timed_out": false,
    "number_of_nodes": 2, //节点数量变成了2
    "number_of_data_nodes": 2,
    "active_primary_shards": 0,
    "active_shards": 0,
    "relocating_shards": 0,
    "initializing_shards": 0,
    "unassigned_shards": 0,
    "delayed_unassigned_shards": 0,
    "number_of_pending_tasks": 0,
    "number_of_in_flight_fetch": 0,
    "task_max_waiting_in_queue_millis": 0,
    "active_shards_percent_as_number": 100.0
}
```

#### 3. 启动第三个节点
启动后，再次查看集群信息：

访问方式和地址不变
```json
{
    "cluster_name": "my-es",
    "status": "green",
    "timed_out": false,
    "number_of_nodes": 3, //节点数量变成了3
    "number_of_data_nodes": 3,
    "active_primary_shards": 0,
    "active_shards": 0,
    "relocating_shards": 0,
    "initializing_shards": 0,
    "unassigned_shards": 0,
    "delayed_unassigned_shards": 0,
    "number_of_pending_tasks": 0,
    "number_of_in_flight_fetch": 0,
    "task_max_waiting_in_queue_millis": 0,
    "active_shards_percent_as_number": 100.0
}
```

## 使用测试

#### 1. 向节点 es-9300 添加索引
- 请求方式：PUT
- 请求地址：http://localhost:9300/user

向es-9300服务添加了一个索引：user
```json
{
    "acknowledged": true,
    "shards_acknowledged": true,
    "index": "user"
}
```

#### 2. 通过节点 es-9400 查看索引
- 请求方式：GET
- 请求地址：http://localhost:9400/user

返回结果如下：
```json
{
    "user": {
        "aliases": {},
        "mappings": {},
        "settings": {
            "index": {
                "routing": {
                    "allocation": {
                        "include": {
                            "_tier_preference": "data_content"
                        }
                    }
                },
                "number_of_shards": "1",
                "provided_name": "user",
                "creation_date": "1687940386790",
                "number_of_replicas": "1",
                "uuid": "y_ZFVzSOQnyF55VFHGEjiw",
                "version": {
                    "created": "8080199"
                }
            }
        }
    }
}
```
能够正常查看到该索引，集群能正常工作。