---
title: 7-1. 基本优化
date: 2023-06-30
---
## 硬件
#### 1. 硬盘
Elasticsearch 的基础是 Lucene，所有的索引和文档数据是存储在本地的磁盘中。
```yml
# 一些与磁盘路由晶哥的配置：./config/elasticserch.yml
path.data: /data # data存储的路径
path.logs: /logs # logs文件储存的路径
```

因此磁盘性能是ES最大瓶颈（也计划是所有类型服务器的瓶颈）。Elasticsearch 重度使用磁盘，磁盘能处理的吞吐量越大，节点就越稳定。

一些优化磁盘 I/O 的技巧：
- 使用 SSD：IO效率是机械盘的10倍以上
- 使用RAID 0：可以提升并发吞吐量
    - 不要使用 其他RAID策略，因为分片副本已经提供了高可用保障。
- 使用多块硬盘：每个硬盘的IO总速度都是独立的。
    - 允许 Elasticsearch 通过多个 path.data 目录配置把数据条带化分配到它们上面
- 不要使用远程挂载的存储：会增加额外的网络损耗成本

#### 2. 内存
ES 默认安装后设置的内存是 4GB。对于企业级开发，4GB很小，需要重新设置。

##### 设置ES内存
ES 目录的 config/jvm.options文件是用来配置内存的。
```yaml
################################################################
## IMPORTANT: JVM heap size
################################################################
##
## The heap size is automatically configured by Elasticsearch
## based on the available memory in your system and the roles
## each node is configured to fulfill. If specifying heap is
## required, it should be done through a file in jvm.options.d,
## which should be named with .options suffix, and the min and
## max should be set to the same value. For example, to set the
## heap to 4 GB, create a new file in the jvm.options.d
## directory containing these lines:
##
## -Xms4g
## -Xmx4g

-Xms31g  # 初始启动大小
-Xmx31g  # 可分配的最大内置值
```
确保 Xmx 和 Xms 的大小是相同的，其目的是为了能够在 Java 垃圾回收机制清理完堆区后不需要重新分隔计算堆区的大小而浪费资源，可以减轻伸缩堆大小带来的压力


##### 内存分片策略
ES 堆内存的分配需要满足以下两个原则：
- 不要超过物理内存的 50%：Lucene 的设计目的是把底层 OS 里的数据缓存到内存中。
    - Lucene 的段是分别存储到单个文件中的，这些文件都是不会变化的，所以很利于缓存，同时操作系统也会把这些段文件缓存起来，以便更快的访问。
    - 如果我们设置的堆内存过大，Lucene 可用的内存将会减少，就会严重影响降低 Lucene 的全文本查询性能。
- 堆内存的大小最好不要超过 32GB：在 Java 中，所有对象都分配在堆上，然后有一个 Klass Pointer 指针指向它的类元数据。
    - 这个指针在 64 位的操作系统上为 64 位，64 位的操作系统可以使用更多的内存（2^64）。在 32 位的系统上为 32 位，32 位的操作系统的最大寻址空间为 4GB（2^32）。
    - 64 位的指针意味着更大的浪费，因为你的指针本身大了。浪费内存不算，更糟糕的是，更大的指针在主内存和缓存器（例如 LLC, L1 等）之间移动数据的时候，会占用更多的带宽。

最终策略：
选用64GB内存的服务器作为ES专用服务器，并为ES分片31G的内存
```js
-Xms31g
-Xmx31g
```

#### 3. 其他硬件优化
最好服务器是专门用来搞ES的，提升硬件利用率。

对于CPU来说，核心数越多越好。


## 分片策略
分片设计为ES提供了高可用和高并发的特性，但并不意味着分片和副本越多越好，且分片的数量是不能修改的（会影响的路由计算）。

在创建索引时，要计算好分片数量（副本数量可以动态更改）。其实倒也不必计划的太长远，大不了后期数据量多了，进行阶段性升级，重建ES服务，进行搜索功能升级和迁移。

#### 1. 分片的代价
设计分片时，要了解以下内容：
- 分片是有硬件损耗的：一个分片的底层即为一个 Lucene 索引，会消耗一定文件句柄、内存、以及 CPU 运转。
- 一个节点分片不要过多：每一个搜索请求都需要命中索引中的每一个分片，如果每一个分片都处于不同的节点还好， 但如果多个分片都需要在同一个节点上竞争使用相同的资源就有些糟糕了。
- 相关度统计：用于计算相关度的词项统计信息是基于分片的。如果有许多分片，每一个都只有很少的数据会导致很低的相关度。

#### 2. 设计分片的基本原则
一个业务索引具体需要分配多少分片可能需要架构师和技术人员对业务的增长有个预先的判断，横向扩展应当分阶段进行。一般来说，我们遵循一些原则：
- 分片容量：控制每个分片占用的硬盘容量不超过 ES 的最大 JVM 的堆空间设置
    - 一般设置不超过 32G
    - 如果索引的总容量在 500G 左右，那分片大小不得超过 16 个
- 节点数量：一般一个节点有时候就是一台物理机，如果分片数过多，大大超过了节点数，很可能会导致一个节点上存在多个分片，一旦该节点故障，即使保持了 1 个以上的副本，同样有可能会导致数据丢失，集群无法恢复。
    - 一般都设置分片数不超过节点数的 3 倍
- 副本数量：主分片，副本和节点最大数之间数量，我们分配的时候可以参考以下关系：
    - 节点数<=主分片数*（副本数+1）

#### 3. 推迟分片分配
当节点产生故障时，集群等待1分支后，就会重写规划新的分片
- 中断节点恢复：重新加入的节点会保持其现有的分片数据，不会触发新的分片分配，减少了ES分片时带来的开销
- 中断节点未回复：重写分配分片

可以通过修改参数 delayed_timeout，延长再均衡的时间，可以全局设置也可以在索引级别进行修改:

PUT /_all/_settings 
```json
{
    "settings": {
        "index.unassigned.node_left.delayed_timeout": "5m"  //改为5分钟
    }
}
```




## 查询优化
#### 1. 使用路由
可以使用路由快速计算文档所在分片，如果不使用路由，就需要对所有的分片进行查询。


## 写入优化
ES 的默认配置，是综合了数据可靠性、写入速度、搜索实时性等因素。实际使用时可根据业务场景进行偏向性的优化。

#### 1. 需要优化的方向
针对于搜索性能要求不高，但是对写入要求较高的场景，可以考虑以下几个方面来提升写索引的性能：
- 加大 Translog Flush ，目的是降低 Iops、Writeblock。
- 增加 Index Refresh 间隔，目的是减少 Segment Merge 的次数。
- 整 Bulk 线程池和队列。
- 优化节点间的任务分布。
- 优化 Lucene 层的索引建立，目的是降低 CPU 及 IO。

#### 2. 批量数据提交
ES 提供了 Bulk API 支持批量操作，当我们有大量的写任务时，可以使用 Bulk 来进行批量写入。

通用的策略如下：Bulk 默认设置批量提交的数据量不能超过 100M。数据条数一般是根据文档的大小和服务器性能而定的，但是单次批处理的数据大小应从 5MB～15MB 逐渐增加，当性能没有提升时，把这个数据量作为最大值。

#### 3. 合理使用合并
Lucene 以段的形式存储数据。当有新的数据写入索引时，Lucene 就会自动创建一个新的段。随着数据量的变化，段的数量会越来越多，消耗的多文件句柄数及 CPU 就越多，查询效率就会下降。

由于 Lucene 段合并的计算量庞大，会消耗大量的 I/O，所以 ES 默认采用较保守的策略，让后台定期进行段合并

#### 4. 减少 Refresh 的次数
Lucene 在新增数据时，采用了延迟写入的策略，默认情况下索引的 refresh_interval 为1 秒。

Lucene 将待写入的数据先写到内存中，超过 1 秒（默认）时就会触发一次 Refresh，然后 Refresh 会把内存中的的数据刷新到操作系统的文件缓存系统中。

如果我们对搜索的实效性要求不高，可以将 Refresh 周期延长，例如 30 秒。这样还可以有效地减少段刷新次数，但这同时意味着需要消耗更多的 Heap 内存。

#### 5. 加大 Flush 设置
Flush 的主要目的是把文件缓存系统中的段持久化到硬盘，当 Translog 的数据量达到512MB 或者 30 分钟时，会触发一次 Flush。

index.translog.flush_threshold_size 参数的默认值是 512MB，我们可以进行修改。增加参数值意味着文件缓存系统中可能需要存储更多的数据，所以我们需要为操作系统的文件缓存系统留下足够的空间。

#### 6. 减少副本的数量
ES 为了保证集群的可用性，提供了 Replicas（副本）支持，然而每个副本也会执行分析、索引及可能的合并过程，所以 Replicas 的数量会严重影响写索引的效率。

当写索引时，需要把写入的数据都同步到副本节点，副本节点越多，写索引的效率就越慢。

如果需要大批量进行写入操作， 可以先禁止 Replica 复制 ， 设置index.number_of_replicas: 0 关闭副本。在写入完成后，Replica 修改回正常的状态

